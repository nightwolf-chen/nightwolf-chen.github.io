<!DOCTYPE html>
<html lang="zh-cn">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>FFmpeg，SDL2.0 C语言跨平台播放器（iOS Demo） - Jidong&#39;s Time - A place to think and write.</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="Jidong Chen" />
  <meta name="description" content="最近在做一个视频相关的项目。一开始我们使用开源播放器，遇到不少坑，以至于我要深入去研究一下播放器的原理和实现。我在这个过程中用C实现了一个简" />

  <meta name="keywords" content="Jidong, blog, code" />






<meta name="generator" content="Hugo 0.37.1" />


<link rel="canonical" href="https://www.jidongchen.com/post/2017-04-10-ffmpeg&#43;sdl2.0/" />

<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">







<link href="/dist/even.min.css?v=3.2.0" rel="stylesheet">
<link href="/lib/fancybox/jquery.fancybox-3.1.20.min.css" rel="stylesheet">




<meta property="og:title" content="FFmpeg，SDL2.0 C语言跨平台播放器（iOS Demo）" />
<meta property="og:description" content="最近在做一个视频相关的项目。一开始我们使用开源播放器，遇到不少坑，以至于我要深入去研究一下播放器的原理和实现。我在这个过程中用C实现了一个简" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://www.jidongchen.com/post/2017-04-10-ffmpeg&#43;sdl2.0/" />



<meta property="article:published_time" content="2017-04-10T00:00:00&#43;00:00"/>

<meta property="article:modified_time" content="2017-04-10T00:00:00&#43;00:00"/>











<meta itemprop="name" content="FFmpeg，SDL2.0 C语言跨平台播放器（iOS Demo）">
<meta itemprop="description" content="最近在做一个视频相关的项目。一开始我们使用开源播放器，遇到不少坑，以至于我要深入去研究一下播放器的原理和实现。我在这个过程中用C实现了一个简">


<meta itemprop="datePublished" content="2017-04-10T00:00:00&#43;00:00" />
<meta itemprop="dateModified" content="2017-04-10T00:00:00&#43;00:00" />
<meta itemprop="wordCount" content="3792">



<meta itemprop="keywords" content="" />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="FFmpeg，SDL2.0 C语言跨平台播放器（iOS Demo）"/>
<meta name="twitter:description" content="最近在做一个视频相关的项目。一开始我们使用开源播放器，遇到不少坑，以至于我要深入去研究一下播放器的原理和实现。我在这个过程中用C实现了一个简"/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">Jidong&#39;s Time</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">Home</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">Archives</li>
      </a><a href="/about">
        <li class="mobile-menu-item">About</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">Categories</li>
      </a>
  </ul>
</nav>
  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">Jidong&#39;s Time</a>
</div>

<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">Home</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">Archives</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/about">About</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">Categories</a>
      </li>
  </ul>
</nav>
    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">FFmpeg，SDL2.0 C语言跨平台播放器（iOS Demo）</h1>

      <div class="post-meta">
        <span class="post-time"> 2017-04-10 </span>
        <div class="post-category">
            
              <a href="/categories/ios/"> ios </a>
            
              <a href="/categories/ffmpeg/"> FFmpeg </a>
            
          </div>
        <span class="more-meta"> 约 3792 字 </span>
        <span class="more-meta"> 预计阅读 8 分钟 </span>
        
      </div>
    </header>

    
    
<div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">文章目录</h2>
  
  <div class="post-toc-content">
    <nav id="TableOfContents">
<ul>
<li>
<ul>
<li><a href="#播放器原理简介">播放器原理简介</a></li>
<li><a href="#ffmpeg-sdl2-0">FFmpeg+SDL2.0</a>
<ul>
<li><a href="#ffmpeg-解码流程">FFmpeg 解码流程</a>
<ul>
<li><a href="#打开视频文件">打开视频文件</a></li>
<li><a href="#做好解码准备">做好解码准备</a></li>
<li><a href="#从视频当中读取数据">从视频当中读取数据</a></li>
<li><a href="#解码数据">解码数据</a></li>
</ul></li>
<li><a href="#使用sdl-2-0进行视频呈现">使用SDL 2.0进行视频呈现</a>
<ul>
<li><a href="#sdl-图像渲染">SDL 图像渲染</a>
<ul>
<li><a href="#始化sdl组件">始化SDL组件</a></li>
<li><a href="#创建用于显示的window">创建用于显示的window</a></li>
<li><a href="#给window配置渲染方式和texture">给window配置渲染方式和Texture</a></li>
<li><a href="#实现渲染方法">实现渲染方法</a></li>
<li><a href="#视频主循环">视频主循环</a></li>
</ul></li>
<li><a href="#sdl-音频解码与播放">SDL 音频解码与播放</a>
<ul>
<li><a href="#打开音频设备">打开音频设备</a></li>
<li><a href="#实现音频回调">实现音频回调</a></li>
<li><a href="#音频数据解码">音频数据解码</a></li>
</ul></li>
</ul></li>
</ul></li>
<li><a href="#总结">总结</a></li>
</ul></li>
</ul>
</nav>
  </div>
</div>

    
    

    
    <div class="post-content">
      

<pre><code>最近在做一个视频相关的项目。一开始我们使用开源播放器，遇到不少坑，以至于我要深入去研究一下播放器的原理和实现。我在这个过程中用C实现了一个简单的Player，这里总结记录一下。
</code></pre>

<p>完整的demo源码<a href="https://github.com/nightwolf-chen/JDCFFPlayer">GitHub</a>。</p>

<h2 id="播放器原理简介">播放器原理简介</h2>

<p>视频的播放我们要从视频文件说起。视频文件可以简单的理解为主要的两个流（当然还有额外的信息):视频流和音频流。视频流也可以简单的理解为是连续的图片帧编码而成的，具体的编码算法那就博大精深了，比如现在市面上比较流行的h264，不过这些编解码算法mmfpeg都已经封装成库了。音频流就是可以播放的音频了，是声音采样信号PCM经过一定的编码的数据流，比较常见的有aac。</p>

<p>明白了视频文件的结构，我们就有了一个很直接的的播放流程：将视频流解码出来逐帧播放与此同时播放声音流，我们需要特别注意的就是视频和音频的同步的问题，视频文件里面包含了足够的信息让我么来进行同步。
是播放的流程如图：
<img src="/_image/2017-04-10 ffmpeg+sdl2.0/Player.jpg" alt="" /></p>

<h2 id="ffmpeg-sdl2-0">FFmpeg+SDL2.0</h2>

<p>SDL是Simple Direct Media Layer，是C实现的跨平台底层库，我在播放器实现里主要使用到他的图像渲染以及音频能力。
我重点关注解码以及同步实现。我需要几个主要线程来运行不同的任务。
&gt;* 视频解包线程(decode_thread)：这个线程将视频文件进行解包，将视频流和音频流解析成packet，然后分发到视频解码线程和音频解码线程。
&gt;* 视频解码线程(video_thread):这个线程进行实际的视频解码操作，将packet解码成实际的AVFrame，然后交个渲染层。
&gt;* 音频线程(audio_thread):SDL音频本运行在一个独立线程，我们需要实现相关回调为其提供数据。</p>

<p>在播放器里面我创建了三个队列，需要在这里说明一下，以防混淆。</p>

<table>
<thead>
<tr>
<th>队列名称</th>
<th>队列作用</th>
</tr>
</thead>

<tbody>
<tr>
<td>Video Packet队列（videoQueue)</td>
<td>存放从视频文件中直接读取出来的视频packet包数据。</td>
</tr>

<tr>
<td>Audio Packet队列（audioQueue)</td>
<td>存放从视频文件中直接读取出来的音频packet包数据。</td>
</tr>

<tr>
<td>Video Frame队列（videoFrameQueue)</td>
<td>视频帧队列存放的是已经解码完成的视频帧数据。</td>
</tr>
</tbody>
</table>

<h3 id="ffmpeg-解码流程">FFmpeg 解码流程</h3>

<p>首先定义一个存储播放器上下文的结构体：</p>

<pre><code class="language-c">struct JDCMediaContext {
    
    AVFormatContext *fmtCtx;//视频文件上下文
    
    AVCodec *codecVideo;//视频解码器
    AVCodecContext *codecCtxVideo;//视频解码上下文
    AVStream *videoStream;//视频流
    int videoStreamIdx;//视频流在format的index    
    
    AVCodec *codecAudio;//音频解码器
    AVCodecContext *codecCtxAudio;//音频解码上下文
    AVStream *audioStream;//音频流
    int audioStreamIdx;//音频流在format的indx    
    
    JDCSDLContext *sdlCtx;//SDL2.0 上下文
    
    SDL_Thread *parse_tid;//解包线程tid    
    SDL_Thread *video_tid;//视频解码线程tid    
    
    struct SwsContext *swsCtx;//AVFrame变换上线文
    JDCSDLPacketQueue *audioQueue;//音频packet队列
    JDCSDLPacketQueue *videoQueue;//视频packet队列
    
    JDCSDLPacketQueue *videoFrameQueue;//解码完成的视频帧队列
    
    char filename[1024];//文件名
    
    int quit;//退出标志
};
</code></pre>

<h4 id="打开视频文件">打开视频文件</h4>

<p>首先我们需要打开一个视频文件：</p>

<pre><code class="language-c">JDCMediaContext *jdc_media_open_input(const char *url,JDCError **error)
{
    JDCMediaContext *mCtx = (JDCMediaContext *)av_mallocz(sizeof(JDCMediaContext));
    AVFormatContext *pFmtCtx = avformat_alloc_context();
    
    strcpy(mCtx-&gt;filename, url);
    //打开一个视频文件
    if (avformat_open_input(&amp;pFmtCtx, url, NULL, NULL) != 0) {
        av_free(mCtx);
        return NULL;
    }
    
    mCtx-&gt;fmtCtx = pFmtCtx;
    
    if (avformat_find_stream_info(pFmtCtx, NULL) &lt; 0) {
        av_free(mCtx);
        return NULL;
    }
    
    // Dump information about file onto standard error
    av_dump_format(pFmtCtx, 0, mCtx-&gt;filename, 0);

    //找到文件中的视频流和音频流    
    for(int i = 0 ; i &lt; pFmtCtx-&gt;nb_streams ; i++){
        if(pFmtCtx-&gt;streams[i]-&gt;codecpar-&gt;codec_type == AVMEDIA_TYPE_VIDEO &amp;&amp;
           mCtx-&gt;videoStream == NULL){
            mCtx-&gt;videoStreamIdx = i;
        }
        
        if(pFmtCtx-&gt;streams[i]-&gt;codecpar-&gt;codec_type == AVMEDIA_TYPE_AUDIO &amp;&amp;
           mCtx-&gt;audioStream == NULL){
            mCtx-&gt;audioStreamIdx = i;
        }
    }
    
    
    return mCtx;
}
</code></pre>

<h4 id="做好解码准备">做好解码准备</h4>

<p>找到视频流和音频流以后我们需要找到对应的解码器并且打开流，做好解码的准备。</p>

<pre><code class="language-c">jdc_media_open_stream(mCtx, mCtx-&gt;audioStreamIdx);
jdc_media_open_stream(mCtx, mCtx-&gt;videoStreamIdx);

int jdc_media_open_stream(JDCMediaContext *mCtx , int sIdx){
    
    AVFormatContext *pFormatCtx = mCtx-&gt;fmtCtx;
    AVCodecContext *codecCtx = NULL;
    AVCodec *codec = NULL;
    
    if (sIdx &lt; 0 || sIdx &gt;= pFormatCtx-&gt;nb_streams) {
        return -1;
    }
    
    AVStream *stream = pFormatCtx-&gt;streams[sIdx];
    //找到解码器
    codec = avcodec_find_decoder(stream-&gt;codecpar-&gt;codec_id);
    if (!codec) {
        fprintf(stderr, &quot;Unsupported codec!\n&quot;);
        return -1;
    }
    
    codecCtx = avcodec_alloc_context3(codec);
    //配置解码上下文
    if(avcodec_parameters_to_context(codecCtx, stream-&gt;codecpar) &lt; 0){
        fprintf(stderr, &quot;avcodec parameters to context failed!\n&quot;);
        return -1;
    }

    //SDL 音频配置    
    if (codecCtx-&gt;codec_type == AVMEDIA_TYPE_AUDIO) {
        SDL_AudioSpec wanted_spec;
        SDL_AudioSpec spec;
        wanted_spec.freq = codecCtx-&gt;sample_rate;
        wanted_spec.format = AUDIO_S16SYS;
        wanted_spec.channels = codecCtx-&gt;channels;
        wanted_spec.silence = 0;
        wanted_spec.samples = 1024;
        //音频回调，我在这个回调中向音频设备feed数据。
        wanted_spec.callback = jdc_sdl_audio_callback;
        wanted_spec.userdata = mCtx;
        
        if(SDL_OpenAudio(&amp;wanted_spec, &amp;spec) &lt; 0) {
            fprintf(stderr, &quot;SDL_OpenAudio: %s\n&quot;, SDL_GetError());
            return -1;
        }
    }
    
    //打开流开始解码
    if(avcodec_open2(codecCtx, codec, NULL) &lt; 0) {
        fprintf(stderr, &quot;Unsupported codec!\n&quot;);
        return -1;
    }
    
    switch(codecCtx-&gt;codec_type) {
        case AVMEDIA_TYPE_AUDIO:
            mCtx-&gt;audioStreamIdx = sIdx;
            mCtx-&gt;audioStream = stream;
            mCtx-&gt;codecAudio = codec;
            mCtx-&gt;codecCtxAudio = codecCtx;
            mCtx-&gt;audioQueue = jdc_packet_queue_alloc();
            jdc_packet_queue_init(mCtx-&gt;audioQueue);
            SDL_PauseAudio(0);
            break;
        case AVMEDIA_TYPE_VIDEO:
            mCtx-&gt;videoStreamIdx = sIdx;
            mCtx-&gt;videoStream = stream;
            mCtx-&gt;codecVideo = codec;
            mCtx-&gt;codecCtxVideo = codecCtx;
            mCtx-&gt;videoQueue = jdc_packet_queue_alloc();
            mCtx-&gt;video_tid = SDL_CreateThread(jdc_media_video_thread,
                                               &quot;video thread&quot;,
                                               mCtx);
            jdc_packet_queue_init(mCtx-&gt;videoQueue);
            mCtx-&gt;swsCtx = sws_getContext(mCtx-&gt;codecCtxVideo-&gt;width,
                                           mCtx-&gt;codecCtxVideo-&gt;height,
                                           mCtx-&gt;codecCtxVideo-&gt;pix_fmt,
                                           mCtx-&gt;codecCtxVideo-&gt;width,
                                           mCtx-&gt;codecCtxVideo-&gt;height,
                                           AV_PIX_FMT_YUV420P,
                                           SWS_BILINEAR,
                                           NULL,
                                           NULL,
                                           NULL);
            break;
        default:
            break;
    }
    
    return 0;
}

</code></pre>

<h4 id="从视频当中读取数据">从视频当中读取数据</h4>

<p>配置好解码上下文以后，我们开一个线程专门从视频视频文件里面读取packet，我们将读取到的packet分别放到视频packet队列和音频packet队列。队列的实现我在另一篇文章中讨论:<a href="http://www.jidongchen.com/post/2017-04-13-tong-yong-dui-lie-shi-xian">通用队列实现链接</a>。</p>

<pre><code class="language-c">//这里我用的是SDL的线程创建接口，也可以用标准的pthread接口实现。
 mCtx-&gt;parse_tid = SDL_CreateThread(jdc_media_decode_thread, &quot;decode thread&quot;,mCtx);
 //线程运行的方法
 int jdc_media_decode_thread(void *userData)
{
    JDCMediaContext *mCtx = userData;
    AVFrame *pFrame = NULL;
    pFrame = av_frame_alloc();
    
    if (pFrame == NULL) {
        return -1;
    }
    
    int numBytes;
    numBytes = av_image_get_buffer_size(AV_PIX_FMT_YUV420P,
                                        mCtx-&gt;codecCtxVideo-&gt;width,
                                        mCtx-&gt;codecCtxVideo-&gt;height,
                                        1);
    AVPacket *packet;

    //这个方法的核心就是不断的读取视频文件数据，存储到AVPacket结构
    //视频则放到视频packet队列，音频则放到音频packet队列。    
    int ret = -1;
    do{
        packet = av_packet_alloc();
        ret = av_read_frame(mCtx-&gt;fmtCtx, packet);
        if (ret &gt;= 0) {
            if (packet-&gt;stream_index == mCtx-&gt;videoStream-&gt;index) {
                jdc_packet_queue_push(mCtx-&gt;videoQueue, packet);
            }else if(packet-&gt;stream_index == mCtx-&gt;audioStream-&gt;index){
                jdc_packet_queue_push(mCtx-&gt;audioQueue, packet);
            }
        }
    }while(ret &gt;= 0);
    
    
    return 0;
}
</code></pre>

<h4 id="解码数据">解码数据</h4>

<p>从视频文件拿到的packet需要经过解码才能拿到实际的帧数据AVFrame，我们已经把视频和音频packet分别放到了两个队列。针对视频我需要一个专门进行解码操作，这个线程将解码得到的AVFrame放到一个专门的视频帧队列。播放器主线程从视频帧拿到数据进行渲染。</p>

<pre><code class="language-C">int jdc_media_video_thread(void *data)
{
    JDCMediaContext *mCtx = data;
    mCtx-&gt;videoFrameQueue = jdc_packet_queue_alloc();
    jdc_packet_queue_init(mCtx-&gt;videoFrameQueue);
    
    while(1){
        
        AVFrame *pFrame = av_frame_alloc();
        AVPacket *packet;
        //这个方法从视频packet队列里面取出一个packet进行解码，注意如果队列为空这里会
        //挂起，packet新加到队列则会唤醒此线程。
        if(jdc_packet_queue_get_packet(mCtx-&gt;videoQueue, (void **)&amp;packet, 1) &lt; 0) {
            break;
        }
        
         //将packet数据送给解码器。
         int r = avcodec_send_packet(mCtx-&gt;codecCtxVideo, packet);
         if (r != 0) {
            av_packet_unref(packet);
            av_packet_free(&amp;packet);
             continue;
         }
        //尝试获取解码结果        
         r = avcodec_receive_frame(mCtx-&gt;codecCtxVideo, pFrame);
         if (r != 0) {
            av_packet_unref(packet);
            av_packet_free(&amp;packet);
             continue;
         }
        //解码成功，将解码好的视频帧数据放到帧队列。        
        jdc_packet_queue_push(mCtx-&gt;videoFrameQueue, pFrame);
        av_packet_unref(packet);
        av_packet_free(&amp;packet);
    }
    
    
    return 0;
} 
</code></pre>

<p>到这里，我们已经完成了视频帧的解码，得到了渲染需要的数据。音频的数据解码，我们将在SDL的音频线程进行。现在我们进入数据呈现的实现。</p>

<h3 id="使用sdl-2-0进行视频呈现">使用SDL 2.0进行视频呈现</h3>

<h4 id="sdl-图像渲染">SDL 图像渲染</h4>

<h5 id="始化sdl组件">始化SDL组件</h5>

<pre><code class="language-c">int jdc_sdl_init(){
    if (SDL_Init(SDL_INIT_VIDEO | SDL_INIT_AUDIO | SDL_INIT_TIMER)) {
        return -1;
    }
    return 0;
}
</code></pre>

<h5 id="创建用于显示的window">创建用于显示的window</h5>

<p>SDL在iOS平台使用UIWindow实现Window，我这里调用SDL提供的接口创建Window。</p>

<pre><code class="language-c"> SDL_Window *window = NULL;
    
    window = SDL_CreateWindow(&quot;video&quot;,
                              SDL_WINDOWPOS_UNDEFINED,
                              SDL_WINDOWPOS_UNDEFINED,
                              mCtx-&gt;codecCtxVideo-&gt;width,
                              mCtx-&gt;codecCtxVideo-&gt;height,
                              SDL_WINDOW_ALLOW_HIGHDPI | SDL_WINDOW_OPENGL |SDL_WINDOW_BORDERLESS);
</code></pre>

<h5 id="给window配置渲染方式和texture">给window配置渲染方式和Texture</h5>

<pre><code class="language-c">    SDL_Renderer *pRenderer = SDL_CreateRenderer(sdlCtx-&gt;window, -1, 0);
    if (pRenderer == NULL) {
        av_free(sdlCtx);
        return NULL;
    }
    
    sdlCtx-&gt;renderer = pRenderer;
    //注意这里我们使用YUV格式
    SDL_Texture *pTexture = SDL_CreateTexture(pRenderer,
                                              SDL_PIXELFORMAT_IYUV,
                                              SDL_TEXTUREACCESS_STREAMING,
                                              mCtx-&gt;codecCtxVideo-&gt;width,
                                              mCtx-&gt;codecCtxVideo-&gt;height);
    if (pTexture == NULL) {
        av_free(sdlCtx);
        return NULL;
    }
    
    SDL_SetTextureBlendMode(pTexture,SDL_BLENDMODE_BLEND);
</code></pre>

<h5 id="实现渲染方法">实现渲染方法</h5>

<p>真正的将视频绘制到window上，我们拿到AVFrame即可。</p>

<pre><code class="language-c">int video_display(JDCMediaContext *mCtx , void *data) {
    
    AVFrame *pFrameYUV = mCtx-&gt;sdlCtx-&gt;frame;

    AVFrame *pFrame = data;
    JDCSDLContext *sdlCtx = mCtx-&gt;sdlCtx;
    
    struct SwsContext *swsCtx = mCtx-&gt;swsCtx;
    
    sws_scale(swsCtx,
              (uint8_t  const * const *)pFrame-&gt;data,
              pFrame-&gt;linesize,
              0,
              pFrame-&gt;height,
              pFrameYUV-&gt;data,
              pFrameYUV-&gt;linesize);
    
    SDL_Rect sdlRect;
    sdlRect.x = 0;
    sdlRect.y = 0;
    sdlRect.w = pFrame-&gt;width;
    sdlRect.h = pFrame-&gt;height;
    
    SDL_UpdateYUVTexture(sdlCtx-&gt;texture, &amp;sdlRect,
                         pFrameYUV-&gt;data[0], pFrameYUV-&gt;linesize[0],
                         pFrameYUV-&gt;data[1], pFrameYUV-&gt;linesize[1],
                         pFrameYUV-&gt;data[2], pFrameYUV-&gt;linesize[2]);
    
    SDL_RenderClear(sdlCtx-&gt;renderer );
    SDL_RenderCopy( sdlCtx-&gt;renderer, sdlCtx-&gt;texture,NULL, &amp;sdlRect );
    SDL_RenderPresent( sdlCtx-&gt;renderer );
    
    av_frame_unref(pFrame);
    av_frame_free(&amp;pFrame);
    
    return 0;
}
</code></pre>

<h5 id="视频主循环">视频主循环</h5>

<p>接下来我们只需一个timer定时触发事件，从视频帧队列里面拿出数据，绘制到屏幕上即可。</p>

<pre><code class="language-c">    while(1){
        
        SDL_WaitEvent(&amp;event);
        switch(event.type) {
            case FF_QUIT_EVENT:
            case SDL_QUIT:
                mCtx-&gt;quit = 1;
                SDL_Quit();
                return 0;
                break;
            case FF_REFRESH_EVENT:
                video_refresh_timer(event.user.data1);
                break;
            default:
                break;
        }
    }
    void video_refresh_timer(void *userdata) {
    
    JDCMediaContext *mCtx = (JDCMediaContext *)userdata;
    
    if(mCtx-&gt;videoStream) {
        if(jdc_packet_queue_size(mCtx-&gt;videoFrameQueue) == 0) {
            schedule_refresh(mCtx, 1);
        } else {
            //这个方法设定timer下一次触发的时间间隔
            //现在我们不考虑同步问题，设定一个估计值。
            schedule_refresh(mCtx, 40);
            void *videoFrameData = NULL;
            //从帧队列拿出帧数据，如果没有则挂起直到有新的frame数据。
            jdc_packet_queue_get_packet(mCtx-&gt;videoFrameQueue, &amp;videoFrameData, 1);
            video_display(mCtx,videoFrameData);
        }
    } else {
        schedule_refresh(mCtx, 100);
    }
}
</code></pre>

<h4 id="sdl-音频解码与播放">SDL 音频解码与播放</h4>

<p>简单来说，使用SDL播放音频有以下几个步骤:
&gt;* 打开音频设备，设置回调。
&gt;* 在回调里面feed音频数据。</p>

<p>实际上，我们之前拿到的音频数据还是AVPacket，我们需要在想音频设备feed之前对其先进行解码。</p>

<h5 id="打开音频设备">打开音频设备</h5>

<pre><code class="language-c">    SDL_AudioSpec wantedSpec;
    SDL_AudioSpec obtainedSpec;
    
    wantedSpec.freq = mCtx-&gt;audioStream-&gt;codecpar-&gt;sample_rate;
    wantedSpec.format = AUDIO_S16;
    wantedSpec.channels = mCtx-&gt;codecCtxAudio-&gt;channels;
    wantedSpec.silence = 0;
    wantedSpec.samples = SDL_AUDIO_BUFFER_SIZE;
    wantedSpec.callback = jdc_sdl_audio_callback;//回调方法
    wantedSpec.userdata = mCtx;
    
    if(SDL_OpenAudio(&amp;wantedSpec, &amp;obtainedSpec) &lt; 0) {
        av_free(sdlCtx);
        fprintf(stderr, &quot;SDL_OpenAudio: %s\n&quot;, SDL_GetError());
        return -1;
    }
    SDL_PauseAudio(0);
</code></pre>

<h5 id="实现音频回调">实现音频回调</h5>

<p>我们在回调里面要做的就是将解码好的数据，按照回调要求的数据量copy到缓冲区就行了。</p>

<pre><code class="language-c">//stream是音频设备缓冲区的指针我们往里面填数据，len表示当前设备要求数据的长度。
//userdata是我们自己的自定义数据.
void jdc_sdl_audio_callback(void *userdata, Uint8 * stream,int len)
{
    JDCMediaContext *mCtx = (JDCMediaContext *)userdata;
    AVCodecContext *codecCtx = mCtx-&gt;codecCtxAudio;
    int len1,audio_size;
    //用来缓存我们解码好的音频数据。
    static uint8_t audio_buf[192000 * 4 / 2];
    static unsigned int audio_buf_size = 0;
    static unsigned int audio_buf_index = 0;
    
    while(len &gt; 0) {
        //标明解码的数据已经用完了，我们需要重新解码一些数据。
        if(audio_buf_index &gt;= audio_buf_size) {
            /* We have already sent all our data; get more */
            audio_size = jdc_sdl_audio_decode_frame(codecCtx,
                                            audio_buf,
                                            sizeof(audio_buf),
                                            mCtx);
            if(audio_size &lt; 0) {
                /* If error, output silence */
                audio_buf_size = 1024;
                memset(audio_buf, 0, audio_buf_size);
            } else {
                audio_buf_size = audio_size;
            }
            audio_buf_index = 0;
        }
        
        len1 = audio_buf_size - audio_buf_index;
        
        if(len1 &gt; len) len1 = len;      
        //往设备缓冲区填数据。  
        memcpy(stream, (uint8_t *)audio_buf + audio_buf_index, len1);
        
        len -= len1;
        stream += len1;
        audio_buf_index += len1;
    }
    
}
</code></pre>

<h5 id="音频数据解码">音频数据解码</h5>

<p>音频数据的解码跟视频数据解码方式基本一致。需要注意的是对于视频数据，一个AVPacket解码出对应一个AVFrame。但是这对于音频数据是不一定的，某些AVPacket可能包含多个frame，这里需要特别处理一下。</p>

<pre><code class="language-c">int jdc_sdl_audio_decode_frame(AVCodecContext *aCodecCtx,
                       uint8_t *audio_buf,
                       int buf_size,
                       JDCMediaContext *mCtx)
{
    AVPacket *pkt = NULL;
    static AVFrame frame;
    
    int len1, data_size = 0;
    
    while(1){
        
        if (pkt != NULL &amp;&amp; pkt-&gt;data != NULL) {
            
            if  (avcodec_send_packet(aCodecCtx, pkt) &lt; 0) {
                av_packet_unref(pkt);
                av_packet_free(&amp;pkt);
                return -1;
            }
            
            data_size = 0;
            //用循环处理多个frame的情况
            while(avcodec_receive_frame(aCodecCtx, &amp;frame) &gt;= 0){
                
                len1 = frame.linesize[0];
                if(len1 &lt; 0) {
                    /* if error, skip frame */
                    break;
                }
                
                int fData_size = 0;
                fData_size = av_samples_get_buffer_size(NULL,
                                                       aCodecCtx-&gt;channels,
                                                       frame.nb_samples,
                                                       aCodecCtx-&gt;sample_fmt,
                                                       1);
                assert(fData_size &lt;= buf_size);
                //将解码好的数据先存到缓冲区，以便后面使用。
                memcpy(audio_buf+data_size, frame.data[0], fData_size);
                fData_size = AudioResampling(aCodecCtx,
                                             &amp;frame,
                                             AV_SAMPLE_FMT_S16,
                                             2,
                                             44100,audio_buf+data_size);
                data_size += fData_size;
            }
            
            if (data_size &gt; 0) {
                av_packet_unref(pkt);
                av_packet_free(&amp;pkt);
                return data_size;
            }
            
            av_packet_unref(pkt);
            av_packet_free(&amp;pkt);
            
        }
        
        if(mCtx-&gt;quit) {
            return -1;
        }
        //从Audio Queue里面拿packet，如果没有则先挂起直到有数据。
        if(jdc_packet_queue_get_packet(mCtx-&gt;audioQueue, (void **)&amp;pkt, 1)&lt; 0) {
            return -1;
        }
    }
    
    return -1;
}
</code></pre>

<p>好了，到这里我们已经实现了音频的播放。</p>

<h2 id="总结">总结</h2>

<p>我在这篇文章里面讨论了如何实现一个简易的播放器，demo可以正常的播放视频，但是没有进度条的功能。播放器的实现思路其实很直接，解码，渲染，同步。目前没有讨论视频同步的问题，我在另外一篇文章中讨论<a href="http://www.jidongchen.com/post/shi-pin-bo-fang-yin-shi-pin-de-tong-bu">视频同步讨论</a>。完整的demo源码请到<a href="https://github.com/nightwolf-chen/JDCFFPlayer">GitHub</a>。</p>

    </div>

    
    <div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">文章作者</span>
    <span class="item-content">Jidong Chen</span>
  </p>
  <p class="copyright-item">
    <span class="item-title">上次更新</span>
    <span class="item-content">2017-04-10</span>
  </p>
  
  <p class="copyright-item">
    <span class="item-title">许可协议</span>
    <span class="item-content">@Jidong Chen 2018</span>
  </p>
</div>

    
    
<div class="post-reward">
  <input type="checkbox" name="reward" id="reward" hidden />
  <label class="reward-button" for="reward">赞赏支持</label>
  <div class="qr-code">
    
    
      <label class="qr-code-image" for="reward">
        <img class="image" src="/wechat-qr-code.png">
        <span>微信打赏</span>
      </label>
    
      <label class="qr-code-image" for="reward">
        <img class="image" src="/alipay-qr-code.png">
        <span>支付宝打赏</span>
      </label>
  </div>
</div>

    <footer class="post-footer">
      

      
      <nav class="post-nav">
        
          <a class="prev" href="/post/2017-04-13-%E9%80%9A%E7%94%A8%E9%98%9F%E5%88%97%E5%AE%9E%E7%8E%B0/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">用C链表实现通用队列Queue</span>
            <span class="prev-text nav-mobile">上一篇</span>
          </a>
        
          <a class="next" href="/post/2017-04-09-json%E6%98%A0%E5%B0%84%E5%BA%93%E5%AE%9E%E7%8E%B0/">
            <span class="next-text nav-default">实现一个JSON映射库</span>
            <span class="next-text nav-mobile">下一篇</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        
  <div id="disqus_thread"></div>
    <script type="text/javascript">
    (function() {
      
      
      if (window.location.hostname === 'localhost') return;

      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      var disqus_shortname = 'jidongchen';
      dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>

  <div id="gitalk-container"></div>
  <link rel="stylesheet" href="/lib/gitalk/gitalk-1.2.2.min.css">
    <script src="/lib/gitalk/gitalk-1.2.2.min.js"></script>
  <script type="text/javascript">
  var gitalk = new Gitalk({
    id: '2017-04-10 00:00:00 \x2b0000 UTC',
    title: 'FFmpeg，SDL2.0 C语言跨平台播放器（iOS Demo）',
    clientID: '96701fa39ca1c2e4d818',
    clientSecret: '2f0e4065509c7535190f0f5b8bffa79c602901e5',
    repo: 'nightwolf-chen.github.io',
    owner: 'nightwolf-chen',
    admin: ['nightwolf-chen'],
    body: decodeURI(location.href)
  });
  gitalk.render('gitalk-container');
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://github.com/gitalk/gitalk">comments powered by gitalk.</a></noscript>

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
      <a href="mailto:jidongchen93@gmail.com" class="iconfont icon-email" title="email"></a>
      <a href="https://stackoverflow.com/users/6760442/bruce-chen" class="iconfont icon-stack-overflow" title="stack-overflow"></a>
      <a href="https://github.com/nightwolf-chen" class="iconfont icon-github" title="github"></a>
  <a href="https://www.jidongchen.com/index.xml" type="application/rss+xml" class="iconfont icon-rss" title="rss"></a>
</div>

<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://gohugo.io">Hugo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  

  <span class="copyright-year">
    &copy; 
    2018
    <span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">Jidong Chen</span>
  </span>
</div>
    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  
<script src="/lib/highlight/highlight.pack.js?v=20171001"></script><script type="text/javascript" src="/lib/jquery/jquery-3.2.1.min.js"></script>
  <script type="text/javascript" src="/lib/slideout/slideout-1.0.1.min.js"></script>
  <script type="text/javascript" src="/lib/fancybox/jquery.fancybox-3.1.20.min.js"></script>


<script type="text/javascript" src="/dist/even.min.js?v=3.2.0"></script>
  <script type="text/javascript">
    window.MathJax = {
      TeX: {equationNumbers: {autoNumber: "AMS"}},
      showProcessingMessages: false,
      messageStyle: 'none'
    };
  </script>
  <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML"></script>


<script>
window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
ga('create', 'UA-54003335-1', 'auto');
ga('send', 'pageview');
</script>
<script async src='//www.google-analytics.com/analytics.js'></script>







</body>
</html>
